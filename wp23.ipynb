{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if GPU is active\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import numpy as np\n",
    "#a library of Python bindings designed to solve computer vision problems\n",
    "import cv2\n",
    "#provides functions for creating and removing a directory (folder),\n",
    "#fetching its contents, changing and identifying the current directory, etc.\n",
    "import os\n",
    "\n",
    "# Model Training using tensorflow mwahahaha\n",
    "import tensorflow as tf\n",
    "#Public Keras utilities.\n",
    "from tensorflow.keras import utils\n",
    "#for optimization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#Sequential groups a linear stack of layers into a tf.keras.Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "#Keras layers API\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#to load dataset\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "#data visuals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#using pretrained CV model VGG19\n",
    "from tensorflow.keras.applications import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
    "test_dir = '../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test'\n",
    "\n",
    "def get_data(data_dir) :\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    dir_list = os.listdir(data_dir)\n",
    "    for i in range(len(dir_list)):\n",
    "        print(\"Obtaining images of\", dir_list[i], \"...\")\n",
    "        for image in os.listdir(data_dir + \"/\" + dir_list[i]):\n",
    "            img = cv2.imread(data_dir + '/' + dir_list[i] + '/' + image)\n",
    "            img = cv2.resize(img, (32, 32))\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "    \n",
    "    return images, labels\n",
    "        \n",
    "X, y = get_data(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n",
    "           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n",
    "           'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y):\n",
    "    np_X = np.array(X)\n",
    "    normalised_X = np_X.astype('float32')/255.0\n",
    "    \n",
    "    label_encoded_y = utils.to_categorical(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(normalised_X, label_encoded_y, test_size = 0.3)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = preprocess_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 29\n",
    "batch = 32\n",
    "epochs = 15\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "adam = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch, epochs=epochs, validation_split=0.2, shuffle = True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "  print('Test accuracy:', test_acc)\n",
    "  print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model):\n",
    "\n",
    "  plt.figure(figsize=(12, 12))\n",
    "  plt.subplot(3, 2, 1)\n",
    "  plt.plot(history.history['accuracy'], label = 'train_accuracy')\n",
    "  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.legend()\n",
    "  plt.subplot(3, 2, 2)\n",
    "  plt.plot(history.history['loss'], label = 'train_loss')\n",
    "  plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "plot_results(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
